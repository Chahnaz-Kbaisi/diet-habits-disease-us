{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "import pymongo\n",
    "from config import MONGODB_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Splinter Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAC\n",
    "# executable_path = { 'executable_path': '/usr/local/bin/chromedriver' }\n",
    "\n",
    "# WINDOWS\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape the List of States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alabama',\n",
       " 'alaska',\n",
       " 'arizona',\n",
       " 'arkansas',\n",
       " 'california',\n",
       " 'colorado',\n",
       " 'connecticut',\n",
       " 'delaware',\n",
       " 'district-of-columbia',\n",
       " 'florida',\n",
       " 'georgia',\n",
       " 'hawaii',\n",
       " 'idaho',\n",
       " 'illinois',\n",
       " 'indiana',\n",
       " 'iowa',\n",
       " 'kansas',\n",
       " 'kentucky',\n",
       " 'louisiana',\n",
       " 'maine',\n",
       " 'maryland',\n",
       " 'massachusetts',\n",
       " 'michigan',\n",
       " 'minnesota',\n",
       " 'mississippi',\n",
       " 'missouri',\n",
       " 'montana',\n",
       " 'nebraska',\n",
       " 'nevada',\n",
       " 'new-hampshire',\n",
       " 'new-jersey',\n",
       " 'new-mexico',\n",
       " 'new-york',\n",
       " 'north-carolina',\n",
       " 'north-dakota',\n",
       " 'ohio',\n",
       " 'oklahoma',\n",
       " 'oregon',\n",
       " 'pennsylvania',\n",
       " 'rhode-island',\n",
       " 'south-carolina',\n",
       " 'south-dakota',\n",
       " 'tennessee',\n",
       " 'texas',\n",
       " 'utah',\n",
       " 'vermont',\n",
       " 'virginia',\n",
       " 'washington',\n",
       " 'west-virginia',\n",
       " 'wisconsin',\n",
       " 'wyoming']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array to hold to the list of states\n",
    "states_list = []\n",
    "\n",
    "# URL to be scraped\n",
    "url = f'https://www.countyhealthrankings.org/app/alabama/2020/downloads'\n",
    "\n",
    "# Open webpage\n",
    "browser.visit(url)\n",
    "\n",
    "# Wait until page loads before scraping\n",
    "time.sleep(3);\n",
    "\n",
    "# Retrieve HTML webpage source\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML webpage source using BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Click on the states dropdownin the webpage\n",
    "browser.find_by_css('.select2-choice')[1].click()\n",
    "\n",
    "# Retrieve HTML webpage source\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML webpage source using BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Scrape the list of states\n",
    "result_divs = soup.find_all(\"div\",{\"class\":\"select2-result-label\"})\n",
    "for div in result_divs:\n",
    "    if len(div.text) > 0:\n",
    "        state = div.text.lower().replace(\" \",\"-\").lstrip().rstrip()\n",
    "        states_list.append(state)\n",
    "states_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape the URLs for all excelsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays to hold to the list of states, years and urls\n",
    "data_urls = []\n",
    "data_state = []\n",
    "data_year = []\n",
    "\n",
    "# Loop through the list of states\n",
    "for state in states_list:\n",
    "    \n",
    "    # URL to be scraped\n",
    "    url = f'https://www.countyhealthrankings.org/app/{state}/2020/downloads'\n",
    "    \n",
    "    # Open webpage\n",
    "    browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:diet-habits-disease-us] *",
   "language": "python",
   "name": "conda-env-diet-habits-disease-us-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
